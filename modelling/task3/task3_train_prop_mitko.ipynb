{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import io\n",
    "import pickle\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense, Embedding, Input, LSTM, Bidirectional, Dropout, MaxPooling1D, Conv1D, TimeDistributed\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataTask3(folder):\n",
    "    result = []\n",
    "    fileNames = glob.glob(folder + \"/*.txt\")\n",
    "    for fileName in fileNames:\n",
    "        articleId = fileName.split(\"/\")[-1].split(\".\")[0]\n",
    "        f = open(fileName, \"r\", encoding=\"utf8\")\n",
    "        data = f.read()\n",
    "        f.close()\n",
    "        sentences = [x for x in data.split(\"\\n\") if x != \"\"]\n",
    "        labels = readLabelTask3(folder + \"/\" + articleId + \".task3.labels\")\n",
    "        result.append({\"id\": articleId, \"data\": data, \"sentences\": sentences, \"labels\": labels})\n",
    "        \n",
    "    return result\n",
    "\n",
    "def readLabelTask3(fileName):\n",
    "    result = []\n",
    "    f = open(fileName, \"r\")\n",
    "    result = f.readlines()\n",
    "    f.close()\n",
    "    result = [x.replace(\"\\n\", \"\").split(\"\\t\") for x in result]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = loadDataTask3(\"train-split/tasks-2-3/train-train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateSentence(sentence, char, start=None, stop=None):\n",
    "    if start is None:\n",
    "        start = 0;\n",
    "        \n",
    "    if stop is None:\n",
    "        stop = len(sentence)\n",
    "        \n",
    "    s = list(sentence)\n",
    "    for i in range(start, stop):\n",
    "        if i < len(s):\n",
    "            if s[i] in '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~ ':\n",
    "                s[i] = \" \"\n",
    "            if s[i] not in [\" \", \"\\n\"]:\n",
    "                s[i] = char\n",
    "    return \"\".join(s)\n",
    "\n",
    "def word2label(word):\n",
    "    if word[0] == \"A\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def sen2label(sen):\n",
    "    result = [word2label(x) for x in sen if x != \"\"]\n",
    "    return result\n",
    "\n",
    "def getTrainData(data):\n",
    "    trainX = []\n",
    "    trainY = []\n",
    "    for x in data:\n",
    "        trainX += x[\"sentences\"]\n",
    "        \n",
    "        dataMask = updateSentence(x[\"data\"], \"A\")\n",
    "        for l in x[\"labels\"]:\n",
    "                dataMask = updateSentence(dataMask, \"B\", int(l[2]), int(l[3]))\n",
    "        outcome = [sen2label(y.split(\" \")) for y in dataMask.split(\"\\n\") if y != \"\"]\n",
    "        trainY += outcome\n",
    "\n",
    "        \n",
    "    return trainX, trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y = getTrainData(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tokenization\n",
    "MAX_VOCAB_SIZE = 50000\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(train_X)\n",
    "word2idx = tokenizer.word_index\n",
    "idx2word = {v:k for k, v in word2idx.items()}\n",
    "num_words = min(MAX_VOCAB_SIZE, len(word2idx) + 1)\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length: 129\n",
      "18931\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length = max(len(s) for s in tokenizer.texts_to_sequences(train_X))\n",
    "print('Max sequence length:', max_sequence_length)\n",
    "print(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 200\n",
    "# load in pre-trained word vectors\n",
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "with open(os.path.join('glove.6B/glove.6B.%sd.txt' % EMBEDDING_DIM)) as f:\n",
    "    # is just a space-separated text file in the format:\n",
    "    # word vec[0] vec[1] vec[2] ...\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec\n",
    "print('Found %s word vectors.' % len(word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "# prepare embedding matrix\n",
    "print('Filling pre-trained embeddings...')\n",
    "\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx.items():\n",
    "    if i < MAX_VOCAB_SIZE:\n",
    "        embedding_vector = word2vec.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all zeros.\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, None, 200)         3786200   \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, None, 32)          32032     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, None, 32)          4128      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, None, 32)          3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, None, 20)          660       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, None, 1)           21        \n",
      "=================================================================\n",
      "Total params: 3,826,145\n",
      "Trainable params: 39,945\n",
      "Non-trainable params: 3,786,200\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "LATENT_DIM = 32\n",
    "\n",
    "print('Building model...')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, EMBEDDING_DIM, weights=[embedding_matrix], trainable=False))\n",
    "#model.add(Bidirectional(LSTM(LATENT_DIM, return_sequences=True, recurrent_dropout=0.1)))\n",
    "model.add(Conv1D(filters=LATENT_DIM, kernel_size=5, padding=\"same\"))\n",
    "model.add(MaxPooling1D(pool_size=3, strides=1, padding=\"same\"))\n",
    "model.add(Conv1D(filters=LATENT_DIM, kernel_size=4, padding=\"same\"))\n",
    "model.add(MaxPooling1D(pool_size=4, strides=1, padding=\"same\"))\n",
    "model.add(Conv1D(filters=LATENT_DIM, kernel_size=3, padding=\"same\"))\n",
    "model.add(MaxPooling1D(pool_size=5, strides=1, padding=\"same\"))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(TimeDistributed(Dense(20, activation=\"relu\")))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "  optimizer=Adam(lr=0.01),\n",
    "  # optimizer=SGD(lr=0.01, momentum=0.9),\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2index = {\n",
    "    \"Appeal_to_Authority\": 0,\n",
    "    \"Appeal_to_fear-prejudice\": 1,\n",
    "    \"Bandwagon\": 2,\n",
    "    \"Black-and-White_Fallacy\": 3,\n",
    "    \"Causal_Oversimplification\": 4,\n",
    "    \"Doubt\": 5,\n",
    "    \"Exaggeration,Minimisation\": 6,\n",
    "    \"Flag-Waving\": 7,\n",
    "    \"Loaded_Language\": 8,\n",
    "    \"Name_Calling,Labeling\": 9,\n",
    "    \"Obfuscation,Intentional_Vagueness,Confusion\": 10,\n",
    "    \"Red_Herring\": 11,\n",
    "    \"Reductio_ad_hitlerum\": 12,\n",
    "    \"Repetition\": 13,\n",
    "    \"Slogans\": 14,\n",
    "    \"Straw_Men\": 15,\n",
    "    \"Thought-terminating_Cliches\": 16,\n",
    "    \"Whataboutism\": 17\n",
    "}\n",
    "\n",
    "index2label = [\n",
    "    \"Appeal_to_Authority\",\n",
    "    \"Appeal_to_fear-prejudice\",\n",
    "    \"Bandwagon\",\n",
    "    \"Black-and-White_Fallacy\",\n",
    "    \"Causal_Oversimplification\",\n",
    "    \"Doubt\",\n",
    "    \"Exaggeration,Minimisation\",\n",
    "    \"Flag-Waving\",\n",
    "    \"Loaded_Language\",\n",
    "    \"Name_Calling,Labeling\",\n",
    "    \"Obfuscation,Intentional_Vagueness,Confusion\",\n",
    "    \"Red_Herring\",\n",
    "    \"Reductio_ad_hitlerum\",\n",
    "    \"Repetition\",\n",
    "    \"Slogans\",\n",
    "    \"Straw_Men\",\n",
    "    \"Thought-terminating_Cliches\",\n",
    "    \"Whataboutism\"\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (12342, 129)\n",
      "Shape of output tensor: (12342, 129, 1)\n",
      "Training model...\n",
      "Train on 9873 samples, validate on 2469 samples\n",
      "Epoch 1/5\n",
      "9873/9873 [==============================] - 12s 1ms/step - loss: 0.0621 - acc: 0.9784 - val_loss: 0.0610 - val_acc: 0.9780\n",
      "Epoch 2/5\n",
      "9873/9873 [==============================] - 7s 680us/step - loss: 0.0526 - acc: 0.9801 - val_loss: 0.0614 - val_acc: 0.9780\n",
      "Epoch 3/5\n",
      "9873/9873 [==============================] - 7s 679us/step - loss: 0.0488 - acc: 0.9801 - val_loss: 0.0668 - val_acc: 0.9780\n",
      "Epoch 4/5\n",
      "9873/9873 [==============================] - 7s 679us/step - loss: 0.0483 - acc: 0.9801 - val_loss: 0.0616 - val_acc: 0.9780\n",
      "Epoch 5/5\n",
      "9873/9873 [==============================] - 7s 705us/step - loss: 0.0449 - acc: 0.9801 - val_loss: 0.0644 - val_acc: 0.9780\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimitar/datasets-v3_1/dss3/lib/python3.4/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "input_sequences = pad_sequences(tokenizer.texts_to_sequences(train_X),\n",
    "                                maxlen=max_sequence_length, padding='post')\n",
    "output_sequences = pad_sequences(train_Y, maxlen=max_sequence_length, padding='post')\n",
    "output_sequences = np.reshape(output_sequences, output_sequences.shape + (1,))\n",
    "\n",
    "print('Shape of data tensor:', input_sequences.shape)\n",
    "print('Shape of output tensor:', output_sequences.shape)\n",
    "\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "print('Training model...')\n",
    "z = np.zeros((len(input_sequences), LATENT_DIM))\n",
    "seed(1)\n",
    "set_random_seed(2)\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "  optimizer=Adam(lr=0.01),\n",
    "  # optimizer=SGD(lr=0.01, momentum=0.9),\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "model.fit(\n",
    "  input_sequences,\n",
    "  output_sequences,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  epochs=EPOCHS,\n",
    "  validation_split=VALIDATION_SPLIT\n",
    ")\n",
    "# with open('model_{:}_{:}.json'.format(label2index[label], version), \"w\") as json_file:\n",
    "#    json_file.write(model.to_json())\n",
    "# model.save_weights('model_{:}_{:}.h5'.format(label2index[label], version))\n",
    "# print(\"Saved model to disk\")\n",
    "pred_Y = model.predict(input_sequences).round()\n",
    "pred_Y = np.reshape(pred_Y, pred_Y.shape[:2])\n",
    "act_Y = np.reshape(output_sequences, output_sequences.shape[:2])\n",
    "\n",
    "f1 = f1_score(act_Y, pred_Y, average='micro')\n",
    "\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "with open('model_prob_cnn_v1.json', \"w\") as json_file:\n",
    "        json_file.write(model.to_json())\n",
    "model.save_weights('model_prob_cnn_v1.h5')\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def trainModel(model, tokenizer, data, label, version):\n",
    "    print('Training for:', label)\n",
    "    train_X, train_Y = getTrainData(data, label)\n",
    "    \n",
    "    input_sequences = pad_sequences(tokenizer.texts_to_sequences(train_X),\n",
    "                                    maxlen=max_sequence_length, padding='post')\n",
    "    output_sequences = pad_sequences(train_Y, maxlen=max_sequence_length, padding='post')\n",
    "    output_sequences = np.reshape(output_sequences, output_sequences.shape + (1,))\n",
    "    print('Shape of data tensor:', input_sequences.shape)\n",
    "    print('Shape of output tensor:', output_sequences.shape)\n",
    "    \n",
    "    VALIDATION_SPLIT = 0.2\n",
    "    BATCH_SIZE = 128\n",
    "    EPOCHS = 5\n",
    "    print('Training model...')\n",
    "    z = np.zeros((len(input_sequences), LATENT_DIM))\n",
    "    seed(1)\n",
    "    set_random_seed(2)\n",
    "    model.compile(\n",
    "      loss='binary_crossentropy',\n",
    "      # optimizer='rmsprop',\n",
    "      optimizer=Adam(lr=0.01),\n",
    "      # optimizer=SGD(lr=0.01, momentum=0.9),\n",
    "      metrics=['accuracy']\n",
    "    )\n",
    "    model.fit(\n",
    "      input_sequences,\n",
    "      output_sequences,\n",
    "      batch_size=BATCH_SIZE,\n",
    "      epochs=EPOCHS,\n",
    "      validation_split=VALIDATION_SPLIT\n",
    "    )\n",
    "    with open('model_{:}_{:}.json'.format(label2index[label], version), \"w\") as json_file:\n",
    "        json_file.write(model.to_json())\n",
    "    model.save_weights('model_{:}_{:}.h5'.format(label2index[label], version))\n",
    "    print(\"Saved model to disk\")\n",
    "    pred_Y = model.predict(input_sequences).round()\n",
    "    pred_Y = np.reshape(pred_Y, pred_Y.shape[:2])\n",
    "    act_Y = np.reshape(output_sequences, output_sequences.shape[:2])\n",
    "\n",
    "    f1 = f1_score(act_Y, pred_Y, average='micro')\n",
    "    print(f1)\n",
    "    return f1\n",
    "    \n",
    "    #with open('model_{:}_{:}.pickle'.format(label2index[label], version), 'wb') as handle:\n",
    "    #    pickle.dump(r, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = loadDataTask3(\"train-split/tasks-2-3/train-dev/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_X, dev_Y = getTrainData(dev_data)\n",
    "input_sequences_dev = pad_sequences(tokenizer.texts_to_sequences(dev_X),\n",
    "                                maxlen=max_sequence_length, padding='post')\n",
    "output_sequences_dev = pad_sequences(dev_Y, maxlen=max_sequence_length, padding='post')\n",
    "output_sequences_dev = np.reshape(output_sequences_dev, output_sequences_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027375201288244767\n"
     ]
    }
   ],
   "source": [
    "pred_Y = model.predict(input_sequences_dev).round()\n",
    "pred_Y = np.reshape(pred_Y, pred_Y.shape[:2])\n",
    "#act_Y = np.reshape(output_sequences_dev, output_sequences.shape[:2])\n",
    "\n",
    "f1 = f1_score(output_sequences_dev, pred_Y, average='micro')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for: Straw_Men\n",
      "Shape of data tensor: (12342, 129)\n",
      "Shape of output tensor: (12342, 129, 1)\n",
      "Training model...\n",
      "Train on 9873 samples, validate on 2469 samples\n",
      "Epoch 1/5\n",
      "9873/9873 [==============================] - 103s 10ms/step - loss: 0.0253 - acc: 0.9883 - val_loss: 6.0737e-04 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "9873/9873 [==============================] - 33s 3ms/step - loss: 8.7881e-04 - acc: 0.9999 - val_loss: 6.0738e-04 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "9873/9873 [==============================] - 31s 3ms/step - loss: 8.6792e-04 - acc: 0.9999 - val_loss: 6.0811e-04 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "9873/9873 [==============================] - 32s 3ms/step - loss: 8.5530e-04 - acc: 0.9999 - val_loss: 6.1260e-04 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "9873/9873 [==============================] - 31s 3ms/step - loss: 8.2190e-04 - acc: 0.9999 - val_loss: 6.2038e-04 - val_acc: 1.0000\n",
      "Saved model to disk\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimitar/datasets-v3_1/dss3/lib/python3.4/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainModel(model, tokenizer, train_data, \"Straw_Men\", \"v005\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [y for y in train_data if y[\"id\"] == \"article776368676\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': \"Trump To Sessions In Series Of Tweets: ‘Stop The Rigged Witch Hunt NOW!’\\n\\nPresident Donald Trump has taken to Twitter in order to call upon Attorney General Jeff Sessions to end the investigation into his alleged Russian collusion.\\nTrump wants the Justice Department to “stop the rigged witch hunt” before it can “stain our country and further.”\\nIn his Twitter post, Trump also blasted the 17 angry Democrats that are doing a conflicted Mueller’s dirty work.\\n..This is a terrible situation and Attorney General Jeff Sessions should stop this Rigged Witch Hunt right now, before it continues to stain our country any further.\\nBob Mueller is totally conflicted, and his 17 Angry Democrats that are doing his dirty work are a disgrace to USA!\\n— Donald J. Trump (@realDonaldTrump) August 1, 2018\\n“..This is a terrible situation and Attorney General Jeff Sessions should stop this Rigged Witch Hunt right now, before it continues to stain our country any further.\\nBon Mueller is totally conflicted, and his 17 angry Democrats that are doing his dirty work are a disgrace to [sic] USA!” Trump wrote.\\nAnd Trump is far from the only American who sees the investigation as a witch hunt.\\nMany Twitter users have taken his side, while many others believe firmly in the Russian conspiracy theory.\\nThe president made his comments in a series of Tweets earlier this morning.\\n“FBI Agent Peter Strzok (on the Mueller team) should have recused himself on day one.\\nHe was out to STOP THE ELECTION OF DONALD TRUMP.\\nHe needed an insurance policy.\\nThose are illegal, improper goals, trying to influence the Election.\\nHe should never, ever been allowed to.....— Donald J. Trump (@realDonaldTrump) August 1, 2018\\n.....remain in the FBI while he himself was being investigated.\\nThis is a real issue.\\nIt won’t go into a Mueller Report because Mueller is going to protect these guys.\\nMueller has an interest in creating the illusion of objectivity around his investigation.” ALAN DERSHOWITZ — Donald J. Trump (@realDonaldTrump) August 1, 2018\\nEnough is enough!!!\\nThis is just a deep state coo attempt (Mueller) to stop the will of We the People!!!\\nIt's time to jail Mueller and cancel this witch hunt!!!\\nLock them all up this has to end!!!\\nComfortably Smug (@ComfortablySmug) August 1, 2018\\nAttorney General Sessions recused himself from overseeing the investigation early in 2017.\\nThe New York Times hypothesized that this was done, in part, to avoid the kind of conflicts such as that which Trump has proposed.\\nLater, a special counsel, Robert S. Mueller III, was appointed to carry out the investigation.\\nTrump’s lawyers, Rudolph W. Giuliani and Jay A. Sekulow, said in a telephone interview that the president was not ordering the inquiry closed but simply expressing his opinion via the social media platform.\\n“It’s not a call to action,” Mr. Giuliani said, adding that it was a sentiment that Mr. Trump and his lawyers have expressed publicly before.\\n“He’s expressing his opinion, but he’s not talking of his special powers he has” as president, Giuliani said.\\n“He doesn’t feel that he has to intervene in the process, nor is he intervening,” said Sekulow.\\nThe special counsel is also looking into some of Trump’s tweets about Attorney General Sessions and the former F.B.I.\\ndirector James Comey and whether the messages were intended to “obstruct the inquiry” into his alleged Russian collusion.\\nSenator Patrick Leahy, a Democrat of Vermont, suggested on Twitter that the president’s directive to Sessions in these recent Tweets was, in fact, obstruction.\\nWhen I was a prosecutor, obstruction of justice was often hard to prove, requiring difficult-to-obtain evidence that the individual’s actions were truly intended to interfere with an ongoing criminal investigation.\\nOh how times have changed.\\nhttps://t.co/CjSFJmng7Z — Sen. Patrick Leahy (@SenatorLeahy) August 1, 2018\\nThe ongoing battle against the Trump presidency and the debate over what constitutes opinion vs. “obstruction of justice” doesn’t appear to have an end date in sight.\\nAlthough, according to Guiliani, Mueller suggested that the Russia obstruction probe would be wrapping up by September 1.\\nWe’ll all be waiting with bated breath.\\n\\n\",\n",
       " 'id': 'article776368676',\n",
       " 'labels': [['776368676', 'Flag-Waving', '314', '343'],\n",
       "  ['776368676', 'Loaded_Language', '378', '386'],\n",
       "  ['776368676', 'Loaded_Language', '447', '457'],\n",
       "  ['776368676', 'Loaded_Language', '706', '717'],\n",
       "  ['776368676', 'Loaded_Language', '1040', '1051'],\n",
       "  ['776368676', 'Name_Calling,Labeling', '386', '409'],\n",
       "  ['776368676', 'Flag-Waving', '571', '623'],\n",
       "  ['776368676', 'Flag-Waving', '664', '738'],\n",
       "  ['776368676', 'Flag-Waving', '828', '957'],\n",
       "  ['776368676', 'Flag-Waving', '998', '1078'],\n",
       "  ['776368676', 'Loaded_Language', '314', '320'],\n",
       "  ['776368676', 'Name_Calling,Labeling', '424', '457'],\n",
       "  ['776368676', 'Loaded_Language', '594', '600'],\n",
       "  ['776368676', 'Name_Calling,Labeling', '664', '717'],\n",
       "  ['776368676', 'Loaded_Language', '928', '934'],\n",
       "  ['776368676', 'Loaded_Language', '974', '992'],\n",
       "  ['776368676', 'Exaggeration,Minimisation', '974', '992'],\n",
       "  ['776368676', 'Name_Calling,Labeling', '998', '1051'],\n",
       "  ['776368676', 'Name_Calling,Labeling', '45', '67'],\n",
       "  ['776368676', 'Loaded_Language', '67', '70'],\n",
       "  ['776368676', 'Name_Calling,Labeling', '276', '297'],\n",
       "  ['776368676', 'Name_Calling,Labeling', '542', '560'],\n",
       "  ['776368676', 'Repetition', '542', '560'],\n",
       "  ['776368676', 'Loaded_Language', '640', '658'],\n",
       "  ['776368676', 'Name_Calling,Labeling', '876', '894'],\n",
       "  ['776368676', 'Name_Calling,Labeling', '1164', '1176'],\n",
       "  ['776368676', 'Loaded_Language', '1461', '1494'],\n",
       "  ['776368676', 'Exaggeration,Minimisation', '1596', '1633'],\n",
       "  ['776368676', 'Slogans', '2017', '2033'],\n",
       "  ['776368676', 'Name_Calling,Labeling', '2050', '2075'],\n",
       "  ['776368676', 'Flag-Waving', '2085', '2118'],\n",
       "  ['776368676', 'Loaded_Language', '2132', '2148'],\n",
       "  ['776368676', 'Name_Calling,Labeling', '2164', '2174'],\n",
       "  ['776368676', 'Loaded_Language', '2178', '2210'],\n",
       "  ['776368676', 'Loaded_Language', '3795', '3820'],\n",
       "  ['776368676', 'Loaded_Language', '4187', '4225'],\n",
       "  ['776368676', 'Exaggeration,Minimisation', '640', '658']],\n",
       " 'sentences': ['Trump To Sessions In Series Of Tweets: ‘Stop The Rigged Witch Hunt NOW!’',\n",
       "  'President Donald Trump has taken to Twitter in order to call upon Attorney General Jeff Sessions to end the investigation into his alleged Russian collusion.',\n",
       "  'Trump wants the Justice Department to “stop the rigged witch hunt” before it can “stain our country and further.”',\n",
       "  'In his Twitter post, Trump also blasted the 17 angry Democrats that are doing a conflicted Mueller’s dirty work.',\n",
       "  '..This is a terrible situation and Attorney General Jeff Sessions should stop this Rigged Witch Hunt right now, before it continues to stain our country any further.',\n",
       "  'Bob Mueller is totally conflicted, and his 17 Angry Democrats that are doing his dirty work are a disgrace to USA!',\n",
       "  '— Donald J. Trump (@realDonaldTrump) August 1, 2018',\n",
       "  '“..This is a terrible situation and Attorney General Jeff Sessions should stop this Rigged Witch Hunt right now, before it continues to stain our country any further.',\n",
       "  'Bon Mueller is totally conflicted, and his 17 angry Democrats that are doing his dirty work are a disgrace to [sic] USA!” Trump wrote.',\n",
       "  'And Trump is far from the only American who sees the investigation as a witch hunt.',\n",
       "  'Many Twitter users have taken his side, while many others believe firmly in the Russian conspiracy theory.',\n",
       "  'The president made his comments in a series of Tweets earlier this morning.',\n",
       "  '“FBI Agent Peter Strzok (on the Mueller team) should have recused himself on day one.',\n",
       "  'He was out to STOP THE ELECTION OF DONALD TRUMP.',\n",
       "  'He needed an insurance policy.',\n",
       "  'Those are illegal, improper goals, trying to influence the Election.',\n",
       "  'He should never, ever been allowed to.....— Donald J. Trump (@realDonaldTrump) August 1, 2018',\n",
       "  '.....remain in the FBI while he himself was being investigated.',\n",
       "  'This is a real issue.',\n",
       "  'It won’t go into a Mueller Report because Mueller is going to protect these guys.',\n",
       "  'Mueller has an interest in creating the illusion of objectivity around his investigation.” ALAN DERSHOWITZ — Donald J. Trump (@realDonaldTrump) August 1, 2018',\n",
       "  'Enough is enough!!!',\n",
       "  'This is just a deep state coo attempt (Mueller) to stop the will of We the People!!!',\n",
       "  \"It's time to jail Mueller and cancel this witch hunt!!!\",\n",
       "  'Lock them all up this has to end!!!',\n",
       "  'Comfortably Smug (@ComfortablySmug) August 1, 2018',\n",
       "  'Attorney General Sessions recused himself from overseeing the investigation early in 2017.',\n",
       "  'The New York Times hypothesized that this was done, in part, to avoid the kind of conflicts such as that which Trump has proposed.',\n",
       "  'Later, a special counsel, Robert S. Mueller III, was appointed to carry out the investigation.',\n",
       "  'Trump’s lawyers, Rudolph W. Giuliani and Jay A. Sekulow, said in a telephone interview that the president was not ordering the inquiry closed but simply expressing his opinion via the social media platform.',\n",
       "  '“It’s not a call to action,” Mr. Giuliani said, adding that it was a sentiment that Mr. Trump and his lawyers have expressed publicly before.',\n",
       "  '“He’s expressing his opinion, but he’s not talking of his special powers he has” as president, Giuliani said.',\n",
       "  '“He doesn’t feel that he has to intervene in the process, nor is he intervening,” said Sekulow.',\n",
       "  'The special counsel is also looking into some of Trump’s tweets about Attorney General Sessions and the former F.B.I.',\n",
       "  'director James Comey and whether the messages were intended to “obstruct the inquiry” into his alleged Russian collusion.',\n",
       "  'Senator Patrick Leahy, a Democrat of Vermont, suggested on Twitter that the president’s directive to Sessions in these recent Tweets was, in fact, obstruction.',\n",
       "  'When I was a prosecutor, obstruction of justice was often hard to prove, requiring difficult-to-obtain evidence that the individual’s actions were truly intended to interfere with an ongoing criminal investigation.',\n",
       "  'Oh how times have changed.',\n",
       "  'https://t.co/CjSFJmng7Z — Sen. Patrick Leahy (@SenatorLeahy) August 1, 2018',\n",
       "  'The ongoing battle against the Trump presidency and the debate over what constitutes opinion vs. “obstruction of justice” doesn’t appear to have an end date in sight.',\n",
       "  'Although, according to Guiliani, Mueller suggested that the Russia obstruction probe would be wrapping up by September 1.',\n",
       "  'We’ll all be waiting with bated breath.']}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4185"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[0][\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
