{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sfblwROam5y4",
    "outputId": "28cb4b64-a080-48da-83b3-516418907c33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Bidirectional, GlobalMaxPool1D, Dense, Dropout\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GhE0uP7Xm5y9"
   },
   "outputs": [],
   "source": [
    "# Set Path\n",
    "path = os.path.abspath('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "flco5dWbm5zA"
   },
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sjk-XIzmm5zB",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(path, 'data', 'raw', 'task1.train.txt'), delimiter='\\t', names=['article', 'id', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "77teID7EOwx5",
    "outputId": "408f4353-7213-4259-b031-84076a6429f4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P4Hd81u9m5zH",
    "outputId": "e3d66be8-02c7-4371-c9d3-9d69c06af106"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['article'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n7lGW8x9OwyC",
    "outputId": "a5bcf122-ae75-48a2-d730-fe5761b5dd4e"
   },
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recode the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wZxvU9c6OwyG"
   },
   "outputs": [],
   "source": [
    "df['target'] = df['label'].map({'propaganda': 1, 'non-propaganda': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer()\n",
    "tokenizer = cvec.build_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    # Remove special chars and punctuation\n",
    "    text = \" \".join(tokenizer(text))\n",
    "    \n",
    "    # lowcase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Lematize\n",
    "    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n",
    "    \n",
    "    # Lematize\n",
    "    text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    text = [word for word in text if not word in stop_words]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yNWHPdH1OwyM",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['article_prep'] = df['article'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y0r0Y1svOwyV",
    "outputId": "7cd9ed0c-5d6c-4817-c5c1-2873c76f9034",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xf8gEvzH2p7E"
   },
   "source": [
    "## Make the splits - dev, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XeMsGUpV2p7F"
   },
   "outputs": [],
   "source": [
    "# The whole sample is split on 3 parts - dev, val, test\n",
    "df_dev, df_val = train_test_split(df, test_size = 0.25, random_state = 42, stratify=df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zNs4PnWo2p7H"
   },
   "outputs": [],
   "source": [
    "df_dev['sample'] = 'dev'\n",
    "df_val['sample'] = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample sizes\n",
    "print(df_dev.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "carq5ueDOwyS",
    "outputId": "dcaba347-0bef-425f-dc4f-ed73a7b4790d"
   },
   "outputs": [],
   "source": [
    "# Check the length of the longest text\n",
    "df_dev['article_prep'].apply(lambda x: len(x.split(\" \"))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['article_prep'].apply(lambda x: len(x.split(\" \"))).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dev.to_pickle(os.path.join(path, 'data', 'processed', 'df_dev_v2.pkl'))\n",
    "df_val.to_pickle(os.path.join(path, 'data', 'processed', 'df_val_v2.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.read_pickle(os.path.join(path, 'data', 'processed', 'df_dev_v2.pkl'))\n",
    "df_val = pd.read_pickle(os.path.join(path, 'data', 'processed', 'df_val_v2.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0wgtTsk42p7O"
   },
   "source": [
    "## Prepare for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fbir8tvG2p7P"
   },
   "outputs": [],
   "source": [
    "features = 'article_prep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h8EXA6aF2p7S",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dev\n",
    "\n",
    "# Prepare the X\n",
    "df_dev_x = df_dev[features]\n",
    "\n",
    "# Prepare the y\n",
    "df_dev_y = df_dev['target'].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eKC9CyiH2p7V"
   },
   "outputs": [],
   "source": [
    "# Val\n",
    "\n",
    "# Prepare the X\n",
    "df_val_x = df_val[features]\n",
    "\n",
    "# Prepare the y\n",
    "df_val_y = df_val['target'].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 6000\n",
    "tokenizer = Tokenizer(num_words = max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(df_dev_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_x_tokens = tokenizer.texts_to_sequences(df_dev_x)\n",
    "df_val_x_tokens = tokenizer.texts_to_sequences(df_val_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 348"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zdC3lZ5vOwyj"
   },
   "outputs": [],
   "source": [
    "df_dev_x_pad = pad_sequences(df_dev_x_tokens, maxlen=max_sequence_length)\n",
    "df_val_x_pad = pad_sequences(df_val_x_tokens, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DCd9r2_cOwyo",
    "outputId": "493a596a-5ee4-4a8e-db52-7c2e3c321430",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_size))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(20, activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 200)         1200000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 64)          59648     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                1300      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,260,969\n",
      "Trainable params: 1,260,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "26989/26989 [==============================] - 435s 16ms/step - loss: 0.2535 - acc: 0.9165\n",
      "Epoch 2/2\n",
      "26989/26989 [==============================] - 446s 17ms/step - loss: 0.0986 - acc: 0.9661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x242ffc11940>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(df_dev_x_pad, df_dev_y, batch_size=128, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26989/26989 [==============================] - 367s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "# dev\n",
    "df_dev_y_pred = model.predict(df_dev_x_pad, verbose=1).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.933853459972863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[23846,   263],\n",
       "       [  127,  2753]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('F1-score: {0}'.format(f1_score(df_dev_y_pred, df_dev_y)))\n",
    "confusion_matrix(df_dev_y_pred, df_dev_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8997/8997 [==============================] - 124s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "# val\n",
    "df_val_y_pred = model.predict(df_val_x_pad, verbose=1).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.8184679958027282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7871,  225],\n",
       "       [ 121,  780]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('F1-score: {0}'.format(f1_score(df_val_y_pred, df_val_y)))\n",
    "confusion_matrix(df_val_y_pred, df_val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q4OwUZ4UOwy2"
   },
   "outputs": [],
   "source": [
    "model.save('LSTM v2 epo2.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LSTM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
